\documentclass[12pt]{article}

\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{verbatim}
\usepackage[utf8]{inputenc}


\topmargin=-1cm
\leftmargin=0cm
%\rightmargin=0cm
\oddsidemargin=0.0cm
\evensidemargin=2cm
\textwidth=16.5cm
\textheight=22cm

\newcommand{\bfx}{\mbox{\boldmath $x$}}
\newcommand{\bfy}{\mbox{\boldmath $y$}}
\newcommand{\bfz}{\mbox{\boldmath $z$}}
\newcommand{\bfv}{\mbox{\boldmath $v$}}
\newcommand{\bfu}{\mbox{\boldmath $u$}}
\newcommand{\bfF}{\mbox{\boldmath $F$}}
\newcommand{\bfJ}{\mbox{\boldmath $J$}}
\newcommand{\bfU}{\mbox{\boldmath $U$}}
\newcommand{\bfY}{\mbox{\boldmath $Y$}}
\newcommand{\bfR}{\mbox{\boldmath $R$}}
\newcommand{\bfg}{\mbox{\boldmath $g$}}
\newcommand{\bfc}{\mbox{\boldmath $c$}}
\newcommand{\bfxi}{\mbox{\boldmath $\xi$}}
\def\be{\begin{equation}}
\def\ee{\end{equation}}
\def\ba{\begin{array}}
\def\ea{\end{array}}
\def\d{\mbox{d}}




\pagestyle{empty}

\begin{document}

\begin{center}
{\huge Hermes1D}\\[2mm]
{\Large an $hp$-FEM solver for ODE}\\
\vspace{0.6cm}
Ondřej Čertík, Pavel Šolín\\
$hp$-FEM group, University of Nevada, Reno\\
http://hpfem.math.unr.edu\\
March 2009
\end{center}

\section{Introduction and motivation}

When one speaks about the numerical solution of ODEs, one usually has in mind
initial value problems for equations of the form

$$
{\d u_1\over\d x}=g_1(u_1, u_2, \dots, u_m, x),
$$
\be\label{one}
\vdots
\ee
$$
{\d u_m\over\d x}=g_m(u_1, u_2, \dots, u_m, x).
$$
These are solved in a finite time interval $(0,T)$ using various time-stepping
methods. There are tons of those and some are quite sophisticated (meaning
multistep, higher-order, adaptive, etc.). But all of them have the following
common shortcomings:
\begin{itemize}
\item We would like to prescribe the initial value at $t = 0$ for some solution
      components and the end-time values at $t = T$ for others. Standard
      time stepping methods do not allow this.
\item Global error control is problematic. One only can regulate the time step
      size locally -- this is something like
      "forward mesh refinement''. But one cannot do "backward mesh refinement''
      or coarsening easily.
\item We would like to prescribe a tolerance for the global error and then
      have the problem solved adaptively until this error tolerance is reached,
      without underresolving or overresolving too much. This is virtually
      impossible with adaptive time stepping methods.
\item Standard time integration methods cannot change their order during the
      computation. For example, an adaptive RK4 method remains 4-order all the
      time. This is an analogy for $h$-refinement in FEM, and obviously it is
      highly inefficient. Correctly, the method should either do small
      low-order steps or large high-order steps to be efficient. We would like
      to see such an analogy of $hp$-refinement in ODE methods.
\item We would like to solve more general ODEs than (\ref{one}).
\end{itemize}
This is why we decided to apply the $hp$-FEM methodology to ODEs and see what happens.

\section{Equations}

We implemented the first version of Hermes1D during one day while returning
from the 2009 SIAM CSE conference. First we considered the form (\ref{one}) but
then we realized that with no extra work we can actually assume a much more
general implicit form

$$
f_1(u_1, u_2, \ldots, u_m, u'_1, u'_2, \ldots, u'_m, x) = 0,
$$
\be\label{two}
\vdots
\ee
$$
f_m(u_1, u_2, \ldots, u_m, u'_1, u'_2, \ldots, u'_m, x) = 0.
$$
Note that (\ref{two}) contains (\ref{one}) as a special case.
In fact, (\ref{two}) can be written shortly as
\be\label{qqq}
\bfF(\bfU, \bfU', x) = 0
\ee
where ${\bfU} = (u_1,\dots,u_m)$ and ${\bfF} = (f_1,\dots,f_m)$.

\subsubsection*{Boundary conditions}

So far, we have considered Dirichlet boundary conditions only, which can be
imposed either at the initial time $t = 0$ or the end-time $t = T$. Exactly one
condition per solution component has to be defined.


\section{$hp$-FEM discretization}

As always, the finite element discretization starts from a weak formulation.
With (\ref{two}), the situation is easy and we have

$$
R_1(\bfY) = \int_0^T f_1(u_1, u_2, \ldots, u_m, u'_1, u'_2, \ldots, u'_m, x)v_1 \, \d t = 0,
$$
\be\label{three}
\vdots
\ee
$$
R_N(\bfY) = \int_0^T f_m(u_1, u_2, \ldots, u_m, u'_1, u'_2, \ldots, u'_m, x)v_N \, \d t = 0.
$$
Here $v_1, v_2, \ldots, v_N$ are all basis functions for all solution
components (we can describe this more accurately if needed).  In the standard
sense, all basis functions corresponding to the solution component $u_i$ are
zero where $u_i$ has a Dirichlet boundary condition.  The vector $\bfY = (y_1,
y_2, \ldots, y_N)$ comprises all unknown coefficients of the finite element
basis functions for all solution components. The meshes for the solution
components $u_1, u_2, \ldots, u_m$ could (more precisely: {\em should}) be
different but for now we assume that they are the same.

\section{Newton's method}

We will drive the residual vector $\bfR = (R_1, R_2, \ldots, R_N)$ to zero
using the Newton's method. For that, we need the Jacobi matrix D$\bfR/$D$\bfY$.

Let $1 \le i, j \le N$.
It is easy to calculate that
$$
\frac{\partial R_i}{\partial y_j}
= \int_0^T \frac{\partial f_{m(i)}}{\partial u_{n(j)}}(u_1, u_2, \ldots, u_m, u'_1, u'_2, \ldots, u'_m, x)v_jv_i
$$
\be\label{newt1}
+ \frac{\partial f_{m(i)}}{\partial u'_{n(j)}}(u_1, u_2, \ldots, u_m, u'_1, u'_2, \ldots, u'_m, x)v'_jv_i \, \d t = 0.
\ee
Here, the function $m(i)$ takes a global index $1 \le i \le N$ and returns the
index of the function $f_{m(i)}$ which is associated with $R_i$. Analogously,
$n(j)$ takes a global index $1 \le j \le N$ and returns the index of the
solution component $u_{n(i)}$ where the basis function $v_j$ belongs to.

The integral in (\ref{newt1}) has two parts because the functions $u_s$ and
$u'_s$ depend on the same solution coefficients.  Do not be confused by the
derivatives with respect to $u'_{n(j)}$ in (\ref{newt1}).  The functions $u_s$
and $u'_s$ are used as independent variables for the differentiation.


\section{Numerical Examples}

The best way to understand the above machinery is to solve examples which we
will do in this section.

\subsection{Classical Linear Harmonic Oscillator}

We want to solve the equation:
$$u''(x)+u(x)=0$$
with boundary conditions $u(0)=0$ and $u'(0)=1$ so the solution is $u(x)=\sin
x$. First let's rewrite the equation into the form (\ref{one}):
$$
{\d u_1\over\d x}=g_1(u_1, u_2, x)=u_2
$$
$$
{\d u_2\over\d x}=g_2(u_1, u_2, x)=-u_1
$$
where $u_1=u$ is the function we seek and $u_2=u'$ is its derivative.
Then let's write it in the form (\ref{two}):
$$
f_1(u_1, u_2, u'_1, u'_2, x) = g_1(u_1, u_2, x)-u_1'=-u_1'+u_2 = 0,
$$
$$
f_2(u_1, u_2, u'_1, u'_2, x) = g_2(u_1, u_2, x)-u_2'=-u_2'-u_1 = 0,
$$
and (\ref{qqq}):
$$
\bfF(\bfU, \bfU', x) = 0
$$
where ${\bfU} = (u_1, u_2)$ and ${\bfF} = (f_1, f_2)=(-u_1'+u_2, -u_2'-u_1)$.
The weak formulation is:
$$
R_1(\bfY) = \int_0^T f_1(u_1, u_2, u'_1, u'_2, x)v_1 \, \d t =
\int_0^T (-u_1'+u_2)v_1 \, \d t
=0,
$$
$$
R_2(\bfY) = \int_0^T f_2(u_1, u_2, u'_1, u'_2, x)v_1 \, \d t =
\int_0^T (-u_2'-u_1)v_2 \, \d t
=0,
$$ To evaluate the Jacobi matrix D$\bfR/$D$\bfY$ for the Newton's iteration, we need the following
Jacobians:
$$
\left({{\rm D}\bfF\over{\rm D}\bfU}\right)_{mn}=
\frac{\partial f_m}{\partial u_n}(u_1, u_2, u'_1, u'_2, x)
=
\left( \begin{array}{c}
-u_1'+u2 \\
-u_2'-u1 \\
\end{array} \right)
\left( \begin{array}{cc}
\overleftarrow{\partial_{u_1}} & \overleftarrow{\partial_{u_2}} \\
\end{array} \right)
=
\left( \begin{array}{cc}
0 & 1 \\
-1 & 0 \\
\end{array} \right)
$$
$$
\left({{\rm D}\bfF\over{\rm D}\bfU'}\right)_{mn}=
\frac{\partial f_m}{\partial u'_n}(u_1, u_2, u'_1, u'_2, x)
=
\left( \begin{array}{c}
-u_1'+u2 \\
-u_2'-u1 \\
\end{array} \right)
\left( \begin{array}{cc}
\overleftarrow{\partial_{u_1'}} & \overleftarrow{\partial_{u_2'}} \\
\end{array} \right)
=
\left( \begin{array}{cc}
-1 & 0 \\
0 & -1 \\
\end{array} \right)
$$
where $\overleftarrow{\partial_{u_1}}$ is a partial derivative with respect to
$u_1$ but acting to the left.

To solve this problem with Hermes, all we have to do is to specify the
following information:
$${\bfF} =
\left( \begin{array}{c}
-u_1'+u2 \\
-u_2'-u1 \\
\end{array} \right)
$$
$$
{{\rm D}\bfF\over{\rm D}\bfU}=
\left( \begin{array}{cc}
0 & 1 \\
-1 & 0 \\
\end{array} \right)
$$
$$
{{\rm D}\bfF\over{\rm D}\bfU'}=
\left( \begin{array}{cc}
-1 & 0 \\
0 & -1 \\
\end{array} \right)
$$
$$u_1(0)=0$$
$$u_2(0)=1$$
and Hermes will solve for $\bfF=0$. This is implemented in
\texttt{examples/sin.py}.

\section{TODO list}

Currently, the code can handle an arbitrary number of equations and solve them
with elements up to the 10th degree. However, the meshes still have to be
equidistant, same for every solution component, and the polynomial degree must
be the same for all elements. The code is not $hp$-adaptive yet. These things
will be fixed as time permits.



\end{document}
